{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "# Parameter Estimation and Maximum Likelihood \n",
    " \n",
    "\n",
    "The concept of **likelihood** and **maximum likelihood estimation (MLE)** have been at the core of much of statistical modeling for about 100 years. In the 21st Century, these ideas continue to be foundational. \n",
    "\n",
    "Understanding the concept of likelihood and the use of MLE methods is key to understanding many parametric statistical methods. Further, widely used machine learning models, including some deep learning models, use MLE. \n",
    "\n",
    "Our goal here is to find **parameter vector $\\theta$ that maximize the likelihood** of a parametric model or distribution, **given the observations, $\\mathbf{X} = x_1, x_2, \\ldots, x_n$**. This concept is the core of **maximum likelihood estimation**.       \n",
    "\n",
    "Stigler -@Stigler_2007 traces the long history of the concepts of likelihood and the MLE. The history starts with workers in the early 19th Century, including Gauss and Bernoulli. Major advances are marked by Fisher's seminal work in the 1920s and 1930s in establishing key properties of the MLE. Today, MLE is a workhorse of many commonly used statistical models, as well as advanced AI models employing deep neural networks.       \n",
    "\n",
    "Unfortunately, the concepts of likelihood and maximum likelihood can appear abstract and hard to understand at first. However, the valuable understanding that a working knowledge of these topics provides for working data scientists is worth the effort.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood   \n",
    "\n",
    "Likelihood is a measure of how likely it is that a set of observations, $\\mathbf{X} = x_1, x_2, \\ldots, x_n$, arises from a **generating process** with a **parametric probability distribution**, $f(\\mathbf{X} | \\theta)$. $f(\\mathbf{X}\\ |\\ \\mathbf{\\theta})$ can be either a probability density function (PDF), for continuous distributions, or a probability mass function (PMF), for discrete distributions. The distribution parameter vector, $\\mathbf{\\theta}$, is fixed.  \n",
    "\n",
    "Now, for each observation, $x_i$, in $\\mathbf{X} = x_1, x_2, \\ldots, x_n$, the probability is just $f(x_i |\\ \\mathbf{\\theta})$. For the set of observations, the **likelihood** is the product of these probabilities: \n",
    "\n",
    "$$\\mathcal{L}(\\mathbf{X} |\\ \\mathbf{\\theta}) = \\prod_{i=1}^n f(x_i | \\mathbf{\\theta})$$\n",
    "\n",
    "In most practical cases, we work with the **log-likelihood**. For a set of observations, $\\mathbf{X} = x_1, x_2, \\ldots, x_n$, the log-likelihood is expressed:    \n",
    "\n",
    "$$l(\\mathbf{X} |\\ \\mathbf{\\theta}) = log\\big( \\mathcal{L}(\\mathbf{X} |\\ \\mathbf{\\theta}) \\big) = \\sum_{i=1}^n log \\Big( f(x_i\\ |\\ \\mathbf{\\theta}) \\Big)$$   \n",
    "\n",
    "Working with the log-likelihood means that we work with the sum of log probabilities rather than the product. If the probabilities are small, the sum is numerically stable. Whereas, the product of many small numbers is a very small number, which can lead to numerical underflow even for 64 or 128 bit floating point arithmetic.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: The Normal likelihood\n",
    "\n",
    "The **Normal likelihood** is the product of Normal probabilities of the observations, $\\mathbf{X} = x_1, x_2, \\ldots, x_n$. Using the properties of the exponential function, for $n$ observations, $\\mathbf{X} = x_1, x_2, \\ldots, x_n$, the likelihood is:   \n",
    "\n",
    "$$\\mathcal{L}(\\mathbf{X} |\\ \\mathbf{\\theta}) = \\prod_{i=1}^n f(x\\ |\\ \\mu,\\sigma^2)  = -\\frac{1}{(2 \\pi \\sigma^2)^{n/2}} exp\\Big[ - \\frac{1}{2 \\sigma^2}  \\sum_{i=1}^n(x_i - \\mu)^2 \\Big]$$\n",
    "\n",
    "The log-likelihood can then be written:  \n",
    "\n",
    "$$l(\\mathbf{X}\\ |\\ \\mu, \\sigma ) = - \\frac{n}{2} log( 2 \\pi \\sigma^2 ) - \\frac{1}{2 \\sigma^2} \\sum_{j=1}^n (x_j - \\mu)^2$$\n",
    "\n",
    "It is clear that the log-likelihood is a function of the parameter vector, $\\theta = [\\mu,\\sigma]$. Notice also that as the number of observations increases so does the likelihood.   \n",
    "\n",
    "To continue executing the code in the cell below to import the required packages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, binom\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from math import sqrt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example will help illustrate the foregoing concepts. The code below plots the likelihood for 5, 10, and 20 samples from a **standard Normal distribution**. A standard Normal distribution has parameter vector $\\theta = [\\mu,\\sigma] = [1, 0]$. In this example, we vary the parameter $\\mu$, and assume the parameter $\\sigma$ is fixed to 1.0. The steps are:     \n",
    "- A random sample is drawn from a standard Normal distribution.    \n",
    "- For the random sample the log-likelihood is computed at each location parameter value. In code, we do this by summing the logarithm of the PDFs for each observation at a value of the parameter $\\mu$. The lambda (anonymous  function) specified the log of the PDF using the [scipy.stats.norm.logpdf](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) function.      \n",
    "- The log-likelihood is plotted for each of the location parameter values.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_likelihood_1(sample_dist, pdf, num_samples, start, stop, linestyle, xlabel = 'x', max_point=0.0, title = '', figsize=(10,8)):\n",
    "    ## Setup for plot\n",
    "    fig, ax = plt.subplots(figsize=figsize) \n",
    "    X = np.arange(start, stop, step=0.05)\n",
    "\n",
    "    ## Loop over the number of samples\n",
    "    for i,samps in enumerate(num_samples): \n",
    "        ## Compute a sample from standard Normal\n",
    "        sample = sample_dist(samps)\n",
    "        ## Iterate over the x values and compute the likelihood\n",
    "        y=[pdf(sample, mu).sum() for mu in X]\n",
    "        ## Plot the likelihood    \n",
    "        _=ax.plot(X, y, linewidth=4, label= str(samps) + ' samples', linestyle=linestyle[i])\n",
    "\n",
    "    ## Add annotations to plot\n",
    "    ax.vlines(max_point, ymin=min(y), ymax=0.0, linewidth=2, linestyles='dotted')\n",
    "    ax.set_ylabel('Log-likelihood')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.show()         \n",
    "\n",
    "\n",
    "sample_dist = lambda x: nr.normal(size=x)\n",
    "pdf = lambda x, y: norm.logpdf(x, loc=y)\n",
    "num_samples = [5, 10, 20]\n",
    "start = -10.0\n",
    "stop = 10.0\n",
    "linestyle = ['solid','dashed','dashdot']\n",
    "plot_likelihood_1(sample_dist, pdf, num_samples, start, stop, linestyle, xlabel='mu', title='Normal log-likelihood for different sample sizes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the following expected properties:    \n",
    "- The maximum of the likelihood is near the actual location parameter value the samples were drawn from, $\\mu=1$.     \n",
    "- As the number of samples increases the curvature of the log-likelihood increases and the width decreases. The width of these curves is a measure of the uncertainty of the parameter estimate. This behavior indicates that the dispersion of the MLE estimate of the $u$ decreases with increasing sample size. In other words, the **uncertainty in maximum likelihood estimates decreases as sample size increases**.       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 3-1:** With the foregoing theory and example in mind, it is time to work with a more realistic example. One might consider modeling the price per square foot of housing using the parametric log-Normal density function. The univariate log-Normal density function has two parameters, $(\\mu,\\sigma)$. Complete the code in the `likelihood_grid` function to compute the likelihood in a 2-dimensional array by the following steps:       \n",
    "> 1. Create a 2-dimensional Numpy array of 0s of dimensions (number of sigma values, number of mu values). You can use the [numpy.zeros](https://numpy.org/doc/stable/reference/generated/numpy.zeros.html). function to do so.    \n",
    "> 2. Iterate over all pairs of mu and sigma values in the grid with `np.ndindex(param_grid[0].shape).` For each parameter vector, compute the likelihood using [scipy.stats.norm.logpdf](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) and fill in the element of the Numpy array.  \n",
    "> Execute the code and examine the resulting plot.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('..//data//housing.csv')\n",
    "print(f\"Check for 247082 rows with shape = {housing.shape}\")\n",
    "\n",
    "## Remove null values and compute log of medium price for square foot\n",
    "housing = housing[housing.loc[:,'medListPriceSqft'].notnull()]\n",
    "housing.loc[:,'log_medListPriceSqft'] = np.log(housing.loc[:,'medListPriceSqft'])\n",
    "\n",
    "## Random sample the log median list price \n",
    "size = 100\n",
    "np.random.seed(10101)\n",
    "log_housing_price_100 = np.random.choice(housing.loc[:,'log_medListPriceSqft'], size=size, replace=False)\n",
    "mu = np.mean(log_housing_price_100)\n",
    "sigma = sqrt(np.var(log_housing_price_100))\n",
    "print(f\"Empirical estimates of sample: mu = {mu}   sigma = {sigma}\")\n",
    "\n",
    "def likelihood_grid(x, mu_range=(mu - 2.0, mu + 2.0), sigma_range=(sigma/2, 2*sigma)): \n",
    "    ## Compute vectors of mu and sigma values and use these to create a grid   \n",
    "    mu_values = np.arange(mu_range[0], mu_range[1], step=0.05)\n",
    "    sigma_values = np.arange(sigma_range[0], sigma_range[1], step = 0.05)\n",
    "    param_grid = np.meshgrid(mu_values, sigma_values)\n",
    "    \n",
    "    ## Add your code below to fill in the grid or \n",
    "    ## Numpy array with likelihood values. Name the array of dimension\n",
    "    ## (# mu values, # sigma values) likelihood. \n",
    "    \n",
    "    \n",
    "    \n",
    "    return likelihood, mu_values, sigma_values   \n",
    "\n",
    "def plot_Normal_likelihood(x, mu_range=(mu - 1.0, mu + 1.0), sigma_range=(sigma - 0.25, sigma + 0.5), levels=200):\n",
    "    likelihood, mu_values, sigma_values = likelihood_grid(x, mu_range=mu_range, sigma_range=sigma_range)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    print('shape of mu_values = '+str(mu_values.shape))\n",
    "    \n",
    "    print('shape of sigma_values = '+str(sigma_values.shape))\n",
    "    print('shape of likelihood = '+str(likelihood.shape))\n",
    "    ax.contour(mu_values, sigma_values, likelihood, levels=levels, cmap='RdGy')\n",
    "    ax.set_title('Contour plot of log-likelihood of log housing price')\n",
    "    ax.set_ylabel('Sigma squared parameter')\n",
    "    ax.set_xlabel('Location parameter')\n",
    "\n",
    "plot_Normal_likelihood(log_housing_price_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Examine the contour plot. Notice that there is a clear maximum with log-likelihood decreasing away from this maximum. Answer the following questions:      \n",
    "> 1. Which parameter values are approximately the maximum of the log-likelihood?     \n",
    "> 2. For which parameter is the log-likelihood not symmetric about the maximum? \n",
    "> 3. How does this asymmetric gradient limit the accuracy of the parameter estimation?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answers:**      \n",
    "> 1.    \n",
    "> 2.     \n",
    "> 3.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Binomial Likelihood   \n",
    "\n",
    "In the foregoing example, we investigated the log-likelihood of the Normal distribution. Now, we will explore a different example of log-likelihood for the Binomial distribution. Some differences include:   \n",
    "- The Binomial distribution models **discrete events**. The Normal distribution is for continuous-valued observations.    \n",
    "- The range of the single parameter, $\\pi$, of the Binomial distribution is restricted to the range $0 \\le \\pi \\le 1$. At least in principle, the range of the location parameter, $\\mu$, of the Normal distribution is in the range $-\\infty \\le \\mu \\le \\infty$, with the scale parameter limited to the range $0 < \\mu \\le \\infty$.    \n",
    "\n",
    "Recall that the Binomial distribution has the following probability mass function (PMF) for $k$ successes in $n$ trials:        \n",
    "\n",
    "$$\n",
    "f(k, n\\ |\\ \\pi) = \\binom{n}{y} \\pi^k (1 - \\pi)^{n-k}\n",
    "$$\n",
    "$$\n",
    "0 \\le \\pi \\le 1\n",
    "$$\n",
    "$$\n",
    "0 \\le k \\le n\n",
    "$$\n",
    "\n",
    "Given this PDF, the log-likelihood is easily found:    \n",
    "\n",
    "$$l(k, n | \\pi) = log \\binom{n}{k} + k\\ log(\\pi) + (n-k)\\ log(1-\\pi)$$\n",
    "\n",
    "You can see that the Binomial log-likelihood has a strong dependence on both the sample size, $n$ and the number of successes, $k$.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 3-2:** Consider how one might use the concept of likelihood to determine if a fair coin is being used in a toss. Let 'heads' be a success. The question is, how likely are the observed results to be from a fair coin for different sample sizes? Perform the following steps:    \n",
    "> 1. Define `num_samples = [25, 50, 100]`.\n",
    "> 2. Assign an anonymous function to the name `sample_dist`, which simulates tosses of a fair coin $(\\pi = 0.5)$ with random draws from a Binomial distribution using [numpy.random.binomial](https://numpy.org/doc/stable/reference/random/generated/numpy.random.binomial.html) with $n=1$.      \n",
    "> 3. Define a function named `pmf`which uses arguments of the values of the observations, $x$, and the probability parameter, $p$ and returns the log-binomial likelihood using the [scipy.stats.binom.logpmf](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.binom.html) function. \n",
    "> 4. Execute the code and examine the result.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p=0.5\n",
    "np.random.seed(4687)\n",
    "\n",
    "## Your code goes below       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start = 0.05\n",
    "stop = 0.95\n",
    "linestyle = ['solid','dashed','dashdot']\n",
    "for _ in range(4):\n",
    "    plot_likelihood_1(sample_dist, pmf, num_samples, start, stop, linestyle, xlabel='p', max_point=p, title='Binomial Likelihood for different sample sizes', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer the following questions:    \n",
    "> 1. How does the shape of the likelihood curve change with sample size? \n",
    "> 2. How does the shape of the likelihood curves change with the random draw for each sample size?    \n",
    "> 3. Are the maximums of the likelihood curves near the expected value of 0.5?  \n",
    "> 4. Based on your above answers, what can you say about the confidence you should have in determining if a coin is fair for these different sample sizes?    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answers:**    \n",
    "> 1.    \n",
    "> 2.    \n",
    "> 3.    \n",
    "> 4.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Solutions Without a Closed Form\n",
    "\n",
    "So far in this discussion, we have only explored cases where the maximum likelihood solution is a closed form. In the foregoing examples, simple algebra produced solutions. In general, this will not be the case. A common example, is logistic regression, which has no closed form maximum likelihood solution exists.   \n",
    "\n",
    "When no closed-form solution is available an approximate solution can be found by numerical **optimization methods** or **root finding methods**. Here, we will briefly examine gradient descent.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent methods\n",
    "\n",
    "The gradient descent method has an intuitive explanation. The maximum of the log-likelihood function can be found by following the **gradient of the log-likelihood function** until a maximum is reached. \n",
    "\n",
    "To formulate this algorithm, we start with the gradient of the log-likelihood function with respect to the parameters, $\\theta$. The gradient is the vector of partial derivatives with respect to each of the dimensions of the parameter vector.   \n",
    "\n",
    "$$\n",
    "grad(l(\\vec{\\theta})) =  \\nabla_\\theta\\ l(\\vec{\\theta}) = \\begin{pmatrix}\n",
    "  \\frac{\\partial l(\\mathbf{X}\\ |\\ \\mathbf{\\theta})}{\\partial \\theta_1} \\\\\n",
    "   \\frac{\\partial l(\\mathbf{X}\\ |\\ \\mathbf{\\theta})}{\\partial \\theta_2}\\\\\n",
    "   \\vdots \\\\\n",
    "   \\frac{\\partial l(\\mathbf{X}\\ |\\ \\mathbf{\\theta})}{\\partial \\theta_n} \n",
    " \\end{pmatrix}\n",
    " $$\n",
    "\n",
    "We will use the notation, $\\hat{\\theta}$, to indicate an estimate of the true parameter vector, $\\vec{\\theta}$. Given a current parameter estimate vector at step n , $\\hat{\\theta}_n$, the improved parameter estimate vector,  $\\hat{\\theta}_{n+1}$, is found:    \n",
    "\n",
    "$$\\hat{\\theta}_{n+1} = \\hat{\\theta}_n + \\gamma\\ \\nabla_\\theta\\ l(\\hat{\\theta_n})$$   \n",
    "\n",
    "The hyperparameter $\\gamma$ is the **learning rate** or **step size**. Determining a learning rate can have a significant effect on the performance of the gradient. This hyperparameter can be chosen manually, often by a search of the hyperparameter space.    \n",
    "#### Stopping condition     \n",
    "\n",
    "Keeping in mind that gradient descent algorithms are approximations, we cannot simply stop the updates (iterations) when a correct solution is reached. Rather, we need to establish a **stopping criteria**. There are several ways one can specify this condition.    \n",
    "\n",
    "1. The stopping criteria can specified in terms of an **error tolerance**. The error tolerance is the minimum amount of change in the parameter vector norm required to continue updates of the parameters. Once the change in the parameter vector norm is less that the error tollerance we tollerate the remaining error and terminate the algorithm.      \n",
    "2. Ideally, an algorithm should stop when the gradient is $0$. However, given noisy data and an approximate algorithm, this condition with  Another way to specify a stopping criteria is as a minimum gradient norm required to contineu updates of the parameters. The **gradient error** is the tolerance of the gradient we will allow when we terminate the algorithm.            \n",
    "\n",
    "#### Adaptive learning rates      \n",
    "\n",
    "Using a fixed $\\gamma$ is far from optimal. As the magnitude of the gradient changes toward the maximum point the optimal step size changes. More sophisticated algorithms use an adaptive method to determine an optimal step at each step. Finding this step size can be found dynamically using a **line search** procedure. The line search typically uses a quadratic approximation to find a maximum (or minimum).     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum or minimum?    \n",
    "\n",
    "The foregoing describes a maximization algorithm. We could just as well formulate this problem as a minimization problem. Using the negative log-likelihood the gradient is followed in the negative direction until convergence.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 3-3:** As you have already seen, maximum likelihood estimation of Normal distribution parameters can be done using simple closed-form solutions. Now, you will use the gradient descent method to estimate these parameters. Using a Bernoulli sample of 100 log housing price values you will compute the '' function to estimate the parameters $\\mu$ and $\\sigma$ by these steps:   \n",
    "> 1. Compute a gradient vector using the `gradient` function provided. Notice that the function returns a vector of the gradient. The gradient has a dimension for each of the parameters of the log-likelihood function.             \n",
    "> 2. Updated the parameter values using the update relationship shown above.    \n",
    "> 3. Compute the norm of the gradient vector with [numpy.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html).   \n",
    "> 4. Append the new estimated parameters to the `mu_values` and `sigma_squared` lists.    \n",
    "> 5. Append the norm of the gradient to the `grad_norm_step` list.   \n",
    "> Execute your code and examine the resulting plots.   \n",
    "\n",
    "> **Note on algorithm:** The algorithm you implement for these exercises is far from state of the art. State-of-the-art algorithms use adaptive methods to adjust the learning rate parameter, $\\gamma$. When gradients are high, these algorithms use a relatively large value of $\\gamma$. The large value of $\\gamma$ allows aggressive learning when the parameter estimates are far from convergence. As the parameter estimate nears convergence, the learning rate, $\\gamma$, is decreased. The lower learning rate prevents the parameter estimates from over-shooting the maximum likelihood point and wandering around the parameter space. The simple algorithm you are implementing uses a fixed learning rate, which results in slower and less steady convergence.             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(params, x):\n",
    "    n = len(x)\n",
    "    g1 = np.divide(np.sum(x - params[0]), params[1])\n",
    "    g2 = -n/(2 * params[1]) + np.divide(np.sum(np.square(x - params[0])), 2 * params[1]**2)\n",
    "    return [g1, g2]\n",
    "\n",
    "def grad_descent(x, params, gamma=0.00001, tolerance=0.1):\n",
    "    mu_values = [params[0]]\n",
    "    sigma_squared = [params[1]]\n",
    "    grad_norm = np.linalg.norm(gradient(params, x))\n",
    "    grad_norm_step = [grad_norm]\n",
    "    while(grad_norm > tolerance):\n",
    " #   for _ in range(200): # Use this iterator for debug\n",
    "        ## Your code goes below   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    plot_grad_descent(mu_values, sigma_squared, grad_norm_step)\n",
    "    return params, mu_values, sigma_squared\n",
    "\n",
    "\n",
    "def plot_grad_descent(mu, sigma, norm):\n",
    "    ## Setup for plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(25, 20), ) \n",
    "    iterations = range(len(mu))\n",
    "    ax[0,0].plot(iterations, mu, linewidth=3)\n",
    "    ax[0,0].set_title('Estimate of mu')\n",
    "    ax[0,0].set_xlabel('Iteration')\n",
    "    ax[0,1].plot(iterations, sigma, linewidth=3)\n",
    "    ax[0,1].set_title('Estimate of sigma squared')\n",
    "    ax[0,1].set_xlabel('Iteration')\n",
    "    ax[1,0].plot(iterations, norm, linewidth=3)\n",
    "    ax[1,0].set_title('Norm of gradient')\n",
    "    ax[1,0].set_xlabel('Iteration')\n",
    "    ax[1,1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "params, mu_values, sigma_squared_values = grad_descent(log_housing_price_100, [2.0, 1.0])\n",
    "\n",
    "def plot_path(x, mu_vals, sigma_squ_vals, mu_range=(mu - 3.0, mu + 1.0), sigma_range=(sigma/4, 6*sigma), levels=600):\n",
    "    ## Plot the log-likelihood   \n",
    "    plot_Normal_likelihood(x, mu_range=mu_range, sigma_range=sigma_range, levels=levels)\n",
    "    ## PLot the path of the gradient descent\n",
    "    plt.plot(mu_vals, sigma_squ_vals, 'bo', lw=3)\n",
    "\n",
    "sigma = sqrt(np.var(log_housing_price_100))\n",
    "mu = np.mean(log_housing_price_100)\n",
    "print(f\"Emperical estiamtes: mu = {mu}  sigma = {sigma}   sigma^2 = {sigma**2}\")\n",
    "print(f\"MLE parameter values: mu = {params[0]}   sigma^2 = {params[1]}\")\n",
    "plot_path(log_housing_price_100, mu_values, sigma_squared_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now answer these questions:    \n",
    "> 1.  Examine the plots of the parameter values and norm of the gradient vs. iteration. Can you see evidence that one parameter is easier to fit than the other?      \n",
    "> 2. Compare the parameter values estimated with the gradient descent algorithm with the values computed using closed form solution. Are your estimated parameters close to the closed-form solutions? If not, something is likely wrong with your gradient descent algorithm.    \n",
    "> 3. Examine the contour plot with the descent path. Does the trajectory of the descent path always follow the maximum gradient direction? In other words, is the trajectory of the descent path always perpendicular to the contour lines of the log-likelihood function?       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answers:**      \n",
    "> 1.     \n",
    "> 2.     \n",
    "> 3.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent (SGD)\n",
    "\n",
    "The simple gradient descent algorithm has limited scalability. The method requires computation and summing of the entire gradient vector. This calculation must be done as a single batch in memory. Computing this full gradient at each step limits scalability. As a result the simple version of gradient descent is referred to as **batch gradient descent**.    \n",
    "\n",
    "To achieve scalability, the **stochastic gradient descent (SGD)** algorithm computes the expected gradient using a **mini-batch**. The mini-batch is a small Bernoulli sample from the full set of cases. As opposed to batch gradient decent, SGD uses a series of gradient approximations computed from the mini-batches. These gradient approximations are inherently noisy or stochastic, giving rise to the method's name.  \n",
    "\n",
    "Using mini-batches greatly increases scalability. While the gradient estimates are less accurate, these estimates can be computed very quickly, and using only a small amount of memory. As a result of scalability, SGD is the workhorse of many large-scale statistical methods. Mini-batch optimization is often referred to as **online optimization** since the optimizer algorithm can update the solution as cases arrive. \n",
    "\n",
    "The basic idea of stochastic optimization is using a Bernoulli random sample of the data to estimate the **expected update** of the model weights. The weight update for SGD then becomes:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t + \\gamma\\ E_{\\hat{p}data}\\Big[ \\nabla_{\\theta} J(\\theta_t) \\Big]$$  \n",
    "\n",
    "where,  \n",
    "$E_{\\hat{p}data} \\big[ \\big]$ is the expected value of the gradient given the Bernoulli sample of the data $\\hat{p}data$.\n",
    "\n",
    "Choosing batch size can require some tuning. If the batch is too small, the gradient estimate will be poor. Further, hardware resources will not be fully utilized. Large batches require significant memory and slow the calculation. \n",
    "\n",
    "Empirically, SGD has good convergence properties. This behavior seems to arise since stochastic gradient samples provide a better exploration of the loss function space. The variations in the gradient from one mini-batch sample to another help the algorithm escape from saddle points or other areas of the loss function with poor convergence properties. In fact, for very large data sets, the SGD algorithm often converges before the first pass through the data is completed. \n",
    "\n",
    "The pseudo-code for the SGD algorithm is:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "define learning_rate\n",
    "proceedure compute_expected_grad(theta, observations):   \n",
    "  for each parameter:\n",
    "      grad[theta_i] = grad(theta_i, observations)\n",
    "  return grad\n",
    "\n",
    "proceedure update_weights(theta, grad):  \n",
    "   theta = theta + learning_rate * grad(theta)\n",
    "   return weights  \n",
    "  \n",
    "Random_sort(cases)          \n",
    "while(|grad| > stopping_criteria):      \n",
    "    mini-batch = sample_next_n(cases)     \n",
    "    grad = compute_expected_grad(theta, mini_batch)      \n",
    "    weights = update_weights(theta, grad)`   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that if the sampling continues for more than one cycle through the cases, the samples are biased. In practice, this small bias does not seem to matter much.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 3-4:** In the previous exercise, you used batch gradient descent to estimate the parameters of the distribution of the log housing prices. Now, you will use SGD to estimate these parameters using a Bernoulli sample of 100 log housing price values, follow these steps (this can be the same sample as Exercise 11-5): Using a Bernoulli sample of 100 log housing price values you will compute the '' function to estimate the parameters $\\mu$ and $\\sigma$ by these steps:   \n",
    "> 1. Bernoulli sample a mini-batch of `index` of size `batch_size` and `replace=False` using [numpy.random.choice](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) \n",
    "> 2. Compute a gradient vector using the mini-batch of observations sampled with the index.     \n",
    "> 3. Updated the parameter values using the gradient estimates from the update relationship shown above.    \n",
    "> 4. Append the new estimated parameter vector to the `out` array using [numpy.append](https://numpy.org/doc/stable/reference/generated/numpy.append.html). You will need to reshape the parameter vector to $(1,2)$.    \n",
    "> 5. Append the norm of the gradient to the `grad_out` list.   \n",
    "> 6. Compute the standard deviation of the gradient and assign it to the variable `err`.    \n",
    "> 7. Increment $i$ by $1$.    \n",
    "> Execute your code and examine the resulting plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sgd(x, estimate, lr=0.01, stopping=0.1, batch_size = 16, max_its = 2000):\n",
    "    out = np.array(estimate).reshape((1,2))\n",
    "    grad_out = [1.0]\n",
    "    err = 10000000.0 # start with a big number \n",
    "    # starting criteria for graident metric\n",
    "    i = 1\n",
    "    indx = range(x.shape[0])\n",
    "    while((err > stopping) and (i < max_its)):   \n",
    "        ## Put your code below    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    out = out.ravel().reshape((i,2))\n",
    "    print('Number of iterations = ' + str(i))   \n",
    "    print('Final gradient value = ' + str(np.std(grad)))\n",
    "    return out, grad_out\n",
    "\n",
    "np.random.seed(1245)\n",
    "params_values, grad_values = sgd(log_housing_price_100, [2.0, 1.0], lr=0.001,\n",
    "                                 stopping=0.1, max_its=10000)\n",
    "plot_grad_descent(params_values[:,0], params_values[:,1], grad_values)\n",
    "\n",
    "sigma = sqrt(np.var(log_housing_price_100))\n",
    "mu = np.mean(log_housing_price_100)\n",
    "print(f\"Emperical estiamtes: mu = {mu}  sigma = {sigma}   sigma^2 = {sigma**2}\")\n",
    "print(f\"MLE parameter values: mu = {params[0]}   sigma^2 = {params[1]}\")\n",
    "plot_path(log_housing_price_100, params_values[:,0], params_values[:,1], \n",
    "          mu_range=(mu - 3.0, mu + 1.0), sigma_range=(sigma/4, 6*sigma), levels=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Examine your plot and answer these questions:   \n",
    "> 1. Examine the plots of the parameter values and norm of the gradient vs. iteration. Can you see evidence that one parameter is easier to fit than the other?   \n",
    "> 2. Notice the instability of the norm of the gradient near the convergence point. Can you account for this instability arising from the mini-batch sampling?     \n",
    "> 3. Compare the parameter values estimated with the gradient descent algorithm with the values computed using a closed-form solution. Are your estimated parameters close to the closed-form solutions? If not, something is likely wrong with your gradient descent algorithm.    \n",
    "> 4. Examine the contour plot with the descent path. Does the trajectory of the descent path always follow the maximum gradient direction? In other words, is the trajectory of the descent path always perpendicular to the contour lines of the log-likelihood function? Can you notice the instability of the algorithm around the convergence point?      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answers:**    \n",
    "> 1.      \n",
    "> 2.     \n",
    "> 3.     \n",
    "> 4.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from os import getcwd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    '''\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "    '''\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "            word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean\n",
    "\n",
    "def test_lookup(func):\n",
    "    freqs = {('sad', 0): 4,\n",
    "             ('happy', 1): 12,\n",
    "             ('oppressed', 0): 7}\n",
    "    word = 'happy'\n",
    "    label = 1\n",
    "    if func(freqs, word, label) == 12:\n",
    "        return 'SUCCESS!!'\n",
    "    return 'Failed Sanity Check!'\n",
    "\n",
    "def lookup(freqs, word, label):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
    "        word: the word to look up\n",
    "        label: the label corresponding to the word\n",
    "    Output:\n",
    "        n: the number of times the word with its corresponding label appears.\n",
    "    '''\n",
    "    n = 0  # freqs.get((word, label), 0)\n",
    "\n",
    "    pair = (word, label)\n",
    "    if (pair in freqs):\n",
    "        n = freqs[pair]\n",
    "    return n\n",
    "\n",
    "def count_tweets(result, tweets, ys):\n",
    "    '''\n",
    "    Input:\n",
    "        result: a dictionary that will be used to map each pair to its frequency\n",
    "        tweets: a list of tweets\n",
    "        ys: a list corresponding to the sentiment of each tweet (either 0 or 1)\n",
    "    Output:\n",
    "        result: a dictionary mapping each pair to its frequency\n",
    "    '''\n",
    "    for y, tweet in zip(ys, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            # define the key, which is the word and label tuple\n",
    "            pair = (word, y)\n",
    "\n",
    "            # if the key exists in the dictionary, increment the count\n",
    "            if pair in result:\n",
    "                result[pair] += 1\n",
    "\n",
    "            # else, if the key is new, add it to the dictionary and set the count to 1\n",
    "            else:\n",
    "                result[pair] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sets of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "# split the data into two pieces, one for training and one for testing\n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg\n",
    "test_x = test_pos + test_neg\n",
    "\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your model using Naive Bayes\n",
    "\n",
    "Naive bayes is an algorithm that could be used for sentiment analysis. It takes a short time to train and also has a short prediction time.\n",
    "\n",
    "#### So how do you train a Naive Bayes classifier?\n",
    "- The first part of training a naive bayes classifier is to identify the number of classes that you have.\n",
    "- You will create a probability for each class.\n",
    "$P(D_{pos})$ is the probability that the document is positive.\n",
    "$P(D_{neg})$ is the probability that the document is negative.\n",
    "Use the formulas as follows and store the values in a dictionary:\n",
    "\n",
    "$$P(D_{pos}) = \\frac{D_{pos}}{D}\\tag{1}$$\n",
    "\n",
    "$$P(D_{neg}) = \\frac{D_{neg}}{D}\\tag{2}$$\n",
    "\n",
    "Where $D$ is the total number of documents, or tweets in this case, $D_{pos}$ is the total number of positive tweets and $D_{neg}$ is the total number of negative tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior and Logprior\n",
    "\n",
    "The prior probability represents the underlying probability in the target population that a tweet is positive versus negative.  In other words, if we had no specific information and blindly picked a tweet out of the population set, what is the probability that it will be positive versus that it will be negative? That is the \"prior\".\n",
    "\n",
    "The prior is the ratio of the probabilities $\\frac{P(D_{pos})}{P(D_{neg})}$.\n",
    "We can take the log of the prior to rescale it, and we'll call this the logprior\n",
    "\n",
    "$$\\text{logprior} = log \\left( \\frac{P(D_{pos})}{P(D_{neg})} \\right) = log \\left( \\frac{D_{pos}}{D_{neg}} \\right)$$.\n",
    "\n",
    "Note that $log(\\frac{A}{B})$ is the same as $log(A) - log(B)$.  So the logprior can also be calculated as the difference between two logs:\n",
    "\n",
    "$$\\text{logprior} = \\log (P(D_{pos})) - \\log (P(D_{neg})) = \\log (D_{pos}) - \\log (D_{neg})\\tag{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive and Negative Probability of a Word\n",
    "To compute the positive probability and the negative probability for a specific word in the vocabulary, we'll use the following inputs:\n",
    "\n",
    "- $freq_{pos}$ and $freq_{neg}$ are the frequencies of that specific word in the positive or negative class. In other words, the positive frequency of a word is the number of times the word is counted with the label of 1.\n",
    "- $N_{pos}$ and $N_{neg}$ are the total number of positive and negative words for all documents (for all tweets), respectively.\n",
    "- $V$ is the number of unique words in the entire set of documents, for all classes, whether positive or negative.\n",
    "\n",
    "We'll use these to compute the positive and negative probability for a specific word using this formula:\n",
    "\n",
    "$$ P(W_{pos}) = \\frac{freq_{pos} + 1}{N_{pos} + V}\\tag{4} $$\n",
    "$$ P(W_{neg}) = \\frac{freq_{neg} + 1}{N_{neg} + V}\\tag{5} $$\n",
    "\n",
    "Notice that we add the \"+1\" in the numerator for additive smoothing.  This [wiki article](https://en.wikipedia.org/wiki/Additive_smoothing) explains more about additive smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log likelihood\n",
    "To compute the loglikelihood of that very same word, we can implement the following equations:\n",
    "\n",
    "$$\\text{loglikelihood} = \\log \\left(\\frac{P(W_{pos})}{P(W_{neg})} \\right)\\tag{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create `freqs` dictionary\n",
    "- Given your `count_tweets()` function, you can compute a dictionary called `freqs` that contains all the frequencies.\n",
    "- In this `freqs` dictionary, the key is the tuple (word, label)\n",
    "- The value is the number of times it has appeared.\n",
    "\n",
    "We will use this dictionary in several parts of this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the freqs dictionary for later uses\n",
    "freqs = count_tweets({}, train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "Given a freqs dictionary, `train_x` (a list of tweets) and a `train_y` (a list of labels for each tweet), implement a naive bayes classifier.\n",
    "\n",
    "##### Calculate $V$\n",
    "- You can then compute the number of unique words that appear in the `freqs` dictionary to get your $V$ (you can use the `set` function).\n",
    "\n",
    "##### Calculate $freq_{pos}$ and $freq_{neg}$\n",
    "- Using your `freqs` dictionary, you can compute the positive and negative frequency of each word $freq_{pos}$ and $freq_{neg}$.\n",
    "\n",
    "##### Calculate $N_{pos}$ and $N_{neg}$\n",
    "- Using `freqs` dictionary, you can also compute the total number of positive words and total number of negative words $N_{pos}$ and $N_{neg}$.\n",
    "\n",
    "##### Calculate $D$, $D_{pos}$, $D_{neg}$\n",
    "- Using the `train_y` input list of labels, calculate the number of documents (tweets) $D$, as well as the number of positive documents (tweets) $D_{pos}$ and number of negative documents (tweets) $D_{neg}$.\n",
    "- Calculate the probability that a document (tweet) is positive $P(D_{pos})$, and the probability that a document (tweet) is negative $P(D_{neg})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise 3-5:**  In the exercise, you will start your code from this point and complete the code to build the sentiment classifier using Naive Bayes classification:\n",
    "\n",
    "##### Calculate the logprior\n",
    "- the logprior is $log(D_{pos}) - log(D_{neg})$\n",
    "\n",
    "##### Calculate log likelihood\n",
    "- Finally, you can iterate over each word in the vocabulary, use your `lookup` function to get the positive frequencies, $freq_{pos}$, and the negative frequencies, $freq_{neg}$, for that specific word.\n",
    "- Compute the positive probability of each word $P(W_{pos})$, negative probability of each word $P(W_{neg})$ using equations 4 & 5.\n",
    "\n",
    "$$ P(W_{pos}) = \\frac{freq_{pos} + 1}{N_{pos} + V}\\tag{4} $$\n",
    "$$ P(W_{neg}) = \\frac{freq_{neg} + 1}{N_{neg} + V}\\tag{5} $$\n",
    "\n",
    "**Note:** We'll use a dictionary to store the log likelihoods for each word.  The key is the word, the value is the log likelihood of that word).\n",
    "\n",
    "- You can then compute the loglikelihood: $log \\left( \\frac{P(W_{pos})}{P(W_{neg})} \\right)\\tag{6}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: dictionary from (word, label) to how often the word appears\n",
    "        train_x: a list of tweets\n",
    "        train_y: a list of labels correponding to the tweets (0,1)\n",
    "    Output:\n",
    "        logprior: the log prior. (equation 3 above)\n",
    "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
    "    '''\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "    # calculate V, the number of unique words in the vocabulary\n",
    "    vocab = set([pair[0] for pair in freqs.keys()])\n",
    "    V = len(vocab)\n",
    "\n",
    "    # calculate N_pos and N_neg\n",
    "    N_pos = N_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        # if the label is positive (greater than zero)\n",
    "        if pair[1] > 0:\n",
    "\n",
    "            # Increment the number of positive words by the count for this (word, label) pair\n",
    "            N_pos += freqs[pair]\n",
    "\n",
    "        # else, the label is negative\n",
    "        else:\n",
    "\n",
    "            # increment the number of negative words by the count for this (word,label) pair\n",
    "            N_neg += freqs[pair]\n",
    "\n",
    "    # Calculate D, the number of documents\n",
    "    D = len(train_y)\n",
    "\n",
    "    # Calculate D_pos, the number of positive documents (*hint: use sum(<np_array>))\n",
    "    D_pos = len(list(filter(lambda x: x > 0, train_y)))\n",
    "\n",
    "    # Calculate D_neg, the number of negative documents (*hint: compute using D and D_pos)\n",
    "    D_neg = len(list(filter(lambda x: x <= 0, train_y)))\n",
    "\n",
    "    ## Put your code below\n",
    "\n",
    "    return logprior, loglikelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT Cell - Check your result to match expected below\n",
    "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)\n",
    "print(logprior)\n",
    "print(len(loglikelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Expected Output**:\n",
    "\n",
    ">0.0\n",
    "\n",
    ">9089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
    "    '''\n",
    "    Input:\n",
    "        tweet: a string\n",
    "        logprior: a number\n",
    "        loglikelihood: a dictionary of words mapping to numbers\n",
    "    Output:\n",
    "        p: the sum of all the logliklihoods of each word in the tweet (if found in the dictionary) + logprior (a number)\n",
    "\n",
    "    '''\n",
    "    # process the tweet to get a list of words\n",
    "    word_l = process_tweet(tweet)\n",
    "    # initialize probability to zero\n",
    "    p = 0\n",
    "    # add the logprior\n",
    "    p += logprior\n",
    "    for word in word_l:\n",
    "       # check if the word exists in the loglikelihood dictionary\n",
    "        if word in loglikelihood:\n",
    "            # add the log likelihood of that word to the probability\n",
    "            p += loglikelihood[word]\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with your own tweet.\n",
    "my_tweet = 'I love machine learning homework.'\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
    "print('The expected output is', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
